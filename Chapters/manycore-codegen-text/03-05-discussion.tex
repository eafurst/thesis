\section{Discussion}\label{sec:discussion}
\input{Chapters/manycore-codegen-fragments/eval-figures}

\begin{figure}[t!]
    \centering
    \includegraphics[scale=0.6]{graphit-figures/heatmap.pdf}
    \caption{Speedups for all benchmarks and real-world input graphs attained from applying the blocked-access method or alignment-based partitioning optimization. Here we examine BFS, PR, CC, BC, and the delta-stepping variant of SSSP.}
    \label{pap:generals:sec:eval:fig:heatmap}
\end{figure}

Figure~\ref{pap:generals:sec:eval:fig:heatmap} shows speedups obtained from applying the blocked-access method or alignment-based partitioning to a wider range of benchmarks and input graphs.
Here we evaluate performance on three real-world social network graphs (LiveJournal, Pokec, and Hollywood) and three road networks (RoadCA, RoadCentral, and RoadUSA).
In addition to BFS and PR we also evaluate on SSSP with delta-stepping, CC, and BC.
%Due to the costs of RTL simulation, we evaluate the \hbvm on 6 of the 10 input graphs and a subset of the total iterations for each application.
For PR we simulate one iteration, and for the remaining applications, we simulate five representative iterations that cover a range of frontier densities and execution behavior.
We use hybrid traversal in the baseline code of BFS, BC, and SSSP to decrease simulation times.
%The speedups reported in Figure~\ref{base_v_opt} come from applying the \hbmc-specific optimizations described in Section~\ref{sec:compilerimpl:hbvm}.
BC, CC, and BFS benefit from alignment-based partitioning, while PR and SSSP use the blocking optimization due to their more compute-intensive nature.
As shown throughout our evaluation, these optimizations better utilize the memory hierarchy and provide up to $4.96\times$ speedup over unoptimized code.

Table~\ref{sec:eval:tab:summary} shows the highest achieved MTEPS for each input graph and benchmark along with the optimization that was used in the generated code.
Alignment-based partitioning provides optimal performance across the most input graphs and benchmarks, and the next best performing optimization is blocking.
This is not surprising, as all of our benchmarks are limited by DRAM, and blocking and alignment-based partitioning are optimizations that makes better use of the memory system.
By adding blocking and alignment-based partitioning, we are able to coalesce read accesses to vertex data.
In addition, with blocking, we are able to make use of explicitly managed, low-latency scratchpad memory in our blocked access method. 
The blocked access method and alignment-based partitioning improve the memory system performance of our benchmarks by targeting a key performance limiter of graph algorithms.

\relatedMTEPSTable

We do not include a direct comparison of our results against other systems; however, Table~\ref{sec:related:tab:mteps} shows performance results for some of the frameworks mentioned in Chapter~\ref{gen:sec:relatedwork}. This table is included to help contextualize the results reported above.
% We only include results from the papers that report performance in MTEPS. We include this table to help contextualize our results.
It is also important to note that we only simulate a small portion of the total manycore architecture. 
The full manycore architecture would have eight HBM channels instead of the two that are simulated along with many more cores.
As a result, the full architecture would have much higher memory bandwidth and more compute resources. 
Because all of our benchmarks are limited by DRAM, we anticipate that we would achieve better performance on the full system due to an increase in memory bandwidth and decrease in memory contention.

\overviewResultsTable